{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "cl_data = pd.read_csv('classification.csv', index_col=False)\n",
    "#cl_data.columns = ['true','pred']\n",
    "#cl_data = cl_data.drop([0], axis=0) # for del first row\n",
    "sc_data = pd.read_csv('scores.csv', index_col=False)\n",
    "sc_data_names = pd.read_csv('scores.csv', index_col=0, nrows=0).columns.tolist()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#cl_data.iloc[1:,0] # begin with two row\n",
    "#d_true = cl_data[cl_data.true=='1']  # leave true ==1\n",
    "#TP = len(cl_data[(cl_data['true']=='1') & (cl_data['pred']=='1')]) # for example\n",
    "TP = len(cl_data[(cl_data.true==1) & (cl_data.pred==1)])\n",
    "FP = len(cl_data[(cl_data.true==0) & (cl_data.pred==1)])\n",
    "FN = len(cl_data[(cl_data.true==1) & (cl_data.pred==0)])\n",
    "TN = len(cl_data[(cl_data.true==0) & (cl_data.pred==0)])\n",
    "print(str(TP)+' '+str(FP)+' '+str(FN)+' '+str(TN))\n",
    "f= open(\"answers_9/1.txt\",\"w+\")\n",
    "f.write(str(TP)+' '+str(FP)+' '+str(FN)+' '+str(TN))\n",
    "f.close()\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 0.56 0.42 0.48\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "true = cl_data.iloc[:,0]\n",
    "pred = cl_data.iloc[:,1]\n",
    "accuracy = metrics.accuracy_score(true, pred, normalize=True)\n",
    "precision = metrics.precision_score(true, pred)\n",
    "#precision = metrics.precision_score(true, pred, labels=None, pos_label='1', average='binary', sample_weight=None) # for example WARNING - pos_lable\n",
    "recall = metrics.recall_score(true, pred)\n",
    "f1_score = metrics.f1_score(true, pred)\n",
    "print(str(np.round((accuracy), decimals=2))+' '+str(np.round((precision), decimals=2))+' '+str(np.round((recall), decimals=2))+' '+str(np.round((f1_score), decimals=2)))\n",
    "f= open(\"answers_9/2.txt\",\"w+\")\n",
    "f.write(str(np.round((accuracy), decimals=2))+' '+str(np.round((precision), decimals=2))+' '+str(np.round((recall), decimals=2))+' '+str(np.round((f1_score), decimals=2)))\n",
    "f.close()\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logreg\n",
      "score_tree\n"
     ]
    }
   ],
   "source": [
    "true = sc_data.iloc[:,0]\n",
    "roc_auc_arr = []\n",
    "precision_70 = [] # three dimensions array\n",
    "arr_70 = pd.DataFrame()\n",
    "\n",
    "for i in np.arange(0,len(sc_data_names)):\n",
    "    score = sc_data.iloc[:,i+1] # i+1 because begin two column\n",
    "    roc_auc_arr.append(metrics.roc_auc_score(true, score))\n",
    "    p0 = pd.DataFrame(list(metrics.precision_recall_curve(true, score))).T # (precision, recall, thresholds)    \n",
    "    prc_70 = p0[p0.iloc[:,1] >= 0.7].values # array: \"precision, recall and thresholds\", where recall >=0.7\n",
    "    #mp = prc_70[prc_70[:,0].argmax()] # find row, where max precision\n",
    "    mp = prc_70[:,0].max() # find value, where max precision\n",
    "    precision_70.append(mp)\n",
    "\n",
    "#print(str(np.round((roc_auc_arr[0]), decimals=2))+' '+str(np.round((roc_auc_arr[1]), decimals=2))+' '+str(np.round((roc_auc_arr[2]), decimals=2))+' '+str(np.round((roc_auc_arr[3]), decimals=2)))\n",
    "print(str(sc_data_names[np.argmax([roc_auc_arr[0],roc_auc_arr[1],roc_auc_arr[2],roc_auc_arr[3]])]))\n",
    "f= open(\"answers_9/3.txt\",\"w+\")\n",
    "f.write(sc_data_names[np.argmax([roc_auc_arr[0],roc_auc_arr[1],roc_auc_arr[2],roc_auc_arr[3]])])\n",
    "f.close()\n",
    "\n",
    "\n",
    "#precision_70.index(max(precision_70)) # find index max precision\n",
    "print(sc_data_names[precision_70.index(max(precision_70))])\n",
    "f= open(\"answers_9/4.txt\",\"w+\")\n",
    "f.write(sc_data_names[precision_70.index(max(precision_70))])\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "270.4px",
    "left": "1187.6px",
    "right": "20px",
    "top": "17px",
    "width": "334.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
